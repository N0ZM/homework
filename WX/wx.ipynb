{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a68a56d",
   "metadata": {},
   "source": [
    "# PyTorchで線形変換WXを実現する2つの方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0769424",
   "metadata": {},
   "source": [
    "PyTorchで線形変換$WX$を実現する方法を考える.  \n",
    "まず普通に$WX$を実装すると以下のようになる."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d19180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb58a846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0000,  3.6000,  4.2000],\n",
      "        [ 6.6000,  8.1000,  9.6000],\n",
      "        [10.2000, 12.6000, 15.0000]])\n"
     ]
    }
   ],
   "source": [
    "W = torch.tensor(\n",
    "    [\n",
    "        [1., 2., 3.], \n",
    "        [4., 5., 6.], \n",
    "        [7., 8., 9.]\n",
    "    ]\n",
    ")\n",
    "X = torch.tensor(\n",
    "    [\n",
    "        [0.1, 0.2, 0.3], \n",
    "        [0.4, 0.5, 0.6], \n",
    "        [0.7, 0.8, 0.9]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(W @ X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db22783f",
   "metadata": {},
   "source": [
    "これは$W$の行ベクトルと$X$の列ベクトルを個別にかけた場合も当然同じ結果になる."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "991471bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(3.0000), tensor(3.6000), tensor(4.2000)]\n",
      "[tensor(6.6000), tensor(8.1000), tensor(9.6000)]\n",
      "[tensor(10.2000), tensor(12.6000), tensor(15.)]\n"
     ]
    }
   ],
   "source": [
    "for w in W:\n",
    "    t = []\n",
    "    for x in X.T:\n",
    "        t.append(w @ x)\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0270c57d",
   "metadata": {},
   "source": [
    "次に, PyTorchのLinearクラスを使って同じことをしてみる."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08b9e768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4000,  3.2000,  5.0000],\n",
      "        [ 3.2000,  7.7000, 12.2000],\n",
      "        [ 5.0000, 12.2000, 19.4000]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "L = nn.Linear(3, 3, bias=False)\n",
    "L.weight = nn.Parameter(\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [1., 2., 3.], \n",
    "            [4., 5., 6.], \n",
    "            [7., 8., 9.], \n",
    "        ]\n",
    "    )\n",
    ")\n",
    "print(L(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912258a3",
   "metadata": {},
   "source": [
    "すると上のように,W@Xを実行したのとは別の結果が出力される.  \n",
    "これはPyTorchのLinearクラスの関数が$WX$ではなく$XW^{\\top}$として実装されているためで,Linearオブジェクトを使って$WX$を実現したい場合は関数実行の際に$X$を転置して与え,出力結果をさらに転置する($(AB)^{\\top} = B^{\\top} A^{\\top}$のため,$(X^{\\top} W^{\\top})^{\\top} = WX$).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "39540cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0000,  3.6000,  4.2000],\n",
      "        [ 6.6000,  8.1000,  9.6000],\n",
      "        [10.2000, 12.6000, 15.0000]], grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "L = nn.Linear(3, 3, bias=False)\n",
    "L.weight = nn.Parameter(\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [1., 2., 3.], \n",
    "            [4., 5., 6.], \n",
    "            [7., 8., 9.], \n",
    "        ]\n",
    "    )\n",
    ")\n",
    "print(L(X.T).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab950b",
   "metadata": {},
   "source": [
    "同様に,$W$が$N \\times M$行列の場合も以下のようになる."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "804d07bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.0000,  8.0000,  9.0000],\n",
      "        [15.8000, 18.4000, 21.0000],\n",
      "        [24.6000, 28.8000, 33.0000]], grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(\n",
    "    [\n",
    "        [0.1, 0.2, 0.3], \n",
    "        [0.4, 0.5, 0.6], \n",
    "        [0.7, 0.8, 0.9], \n",
    "        [1.0, 1.1, 1.2]\n",
    "    ]\n",
    ")\n",
    "\n",
    "L = nn.Linear(3, 3, bias=False)\n",
    "L.weight = nn.Parameter(\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [1., 2., 3., 4.], \n",
    "            [5., 6., 7., 8.], \n",
    "            [9., 10., 11., 12.]\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "print(L(X.T).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c798aa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.0000,  8.0000,  9.0000],\n",
      "        [15.8000, 18.4000, 21.0000],\n",
      "        [24.6000, 28.8000, 33.0000]])\n"
     ]
    }
   ],
   "source": [
    "W = torch.tensor(\n",
    "    [\n",
    "        [1., 2., 3., 4.], \n",
    "        [5., 6., 7., 8.], \n",
    "        [9., 10., 11., 12.]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(W @ X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c21a541",
   "metadata": {},
   "source": [
    "ただ,通常入力データ$X$は行ベクトルを1サンプルとするので$WX$として実装するよりは$XW^{\\top}$とする方が一般的ではある.  \n",
    "これは重みパラメータ$W$を$X$の前にもってくるとサンプル数を固定長にするか$X$を転置するかしなければならなくなるからでもある.  \n",
    "つまり,$W$と$X$は$[N \\times M]$ @ $[M \\times N]$の形にならなければならないが,$X$のサンプル数を1つ増やした場合$X$の形は$[(M + 1) \\times N]$になってしまい,そのまま実行するとバグる.  \n",
    "それを回避するために$W$を$[M \\times N]$の形に設定した上で$L(X^{\\top})$として$X$を転置して与えるという方法もあるが,実行するたびに$X$を転置するのは操作性としてはよくない.  \n",
    "そのため,あえてLinearオブジェクトを使って$WX$を実現する実用的な意味はない.  \n",
    "今回の実装はあくまでPyTorchのLinearオブジェクトの挙動を確認するための実験."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87268ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
